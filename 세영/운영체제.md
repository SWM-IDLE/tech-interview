# 운영체제(OS)

- 컴퓨터 시스템을 효율적으로 관리하고, 사용자가 컴퓨터를 쉽게 다룰 수 있게 해주는 인터페이스

## 운영체제의 역할

- CPU 스케줄링과 프로세스 관리
    - CPU 소유권 할당, 프로세스의 생성과 삭제, 자원 할당 및 반환
- 메모리 관리
    - 한정된 메모리를 어떤 프로세스에 얼만큼 할당해야 하는지 관리
- 디스크 파일 관리
    - 디스크 파일을 어떠한 방법으로 보관할 지 관리
- I/O 디바이스 관리
    - 마우스, 키보드 등 I/O 디바이스와 컴퓨터 간에 데이터를 주고받는 것을 관리

## 운영체제의 구조

![image](https://github.com/SWM-IDLE/tech-interview/assets/78717113/d3bfef0b-6e2f-4a36-adb1-cfaf89599e38)


### 인터페이스

- 커널에 사용자 명령어를 전달하고, 사용자에게 실행 결과를 알려줌
    - CLI, GUI, NUI, OUI

### 커널

- 컴퓨터의 물리적(하드웨어) 자원과 추상화 자원을 관리하는 역할
    - 추상화
        - 물리적으로 하나 뿐인 하드웨어를 여러 사용자들이 번갈아 사용할 수 있도록 마치 여러 개처럼 보이게 하는 기술
        - 커널이 관리함에 따라 각 사용자들은 하나의 하드웨어를 독점하는 것 처럼 느낄 수 있음
        - 물리적 자원 — 추상화한 자원의 예
            - CPU — Task 또는 Process
            - 메모리 — Page 또는 Segment
            - 디스크 — File
            - 네트워크 — 소켓
- 프로세스 관리, 메모리 관리, 입출력 장치 관리, 파일 관리와 같은 운영체제의 핵심적인 기능 수행

![image](https://github.com/SWM-IDLE/tech-interview/assets/78717113/d4b4e7cb-d8fe-4f5c-8026-2fdf3ec9e2d2)


- 커널은 사용자가 System Call을 통해 컴퓨터 자원을 사용할 수 있게 해주는 자원 관리자 → 인터페이스로써의 커널

### 시스템 호출 (System Call)

- 운영체제에서 제공하는 서비스에 접근하기 위핸 프로그래밍 인터페이스
- 프로그램에서 시스템콜을 호출 → 운영체제의 커널에 있는 함수가 실행 → 다양한 운영체제 서비스 이용(하드웨어 자원에 접근, 프로세스 간 통신, 파일 입출력, 메모리 관리 등)
- 운영체제는 시스템콜을 통해 프로그램들이 운영체제의 서비스를 공유하도록 함 → 하드웨어를 안전하게 관리, 충돌 방지

### 드라이버

- 운영체제와 장치 간의 인터페이스를 담당하는 소프트웨어
- 운영체제는 하드웨어 자원을 직접 제어하지 않고, 드라이버를 통해 하드웨어 자원에 접근함

# 프로세스와 스레드

## 프로세스

- 프로그램을 메모리 상에서 실행중인 작업 (Task)
    - 프로그램
        - 하드 디스크 등에 저장되어 있는 실행 코드
        - 프로그램 자체는 생명이 없고 실행되기를 기다리는 명령어와 정적인 데이터의 묶음
        - 프로그램이 자원을 할당 받고 메모리에 적재되면 프로세스가 된다
- 프로세스는 각각 별도의 주소 공간이 할당됨 (독립적)
    
    ![image](https://github.com/SWM-IDLE/tech-interview/assets/78717113/1bed0875-71b5-4a20-ac1b-1bf161e93792)

    - Code: 코드 자체를 구성하는 메모리 영역 — 프로그램 명령
    - Data: 전역 변수, 정적 변수, 배열 등
    - Heap: 동적 할당 시 사용 — new(), malloc() 등
    - Stack: 임시 메모리 영역 — 지역 변수, 매개 변수, 리턴 값 등

![image](https://github.com/SWM-IDLE/tech-interview/assets/78717113/d5495e6b-1410-4862-ab9d-691c45880335)


- 오버플로우(Overflow): 한정된 메모리 공간이 부족하여 데이터가 넘친다는 의미 — 힙이 스택 영역을 침범하면 힙 오버플로우, 스택이 힙 영역을 침범하면 스택 오버플로우

## 스레드

- 프로세스 안에서 실행되는 여러 흐름 단위
- 기본적으로 프로세스마다 최소 1개의 스레드 소유 (메인 스레드 포함)
- 스레드는 Stack만 따로 할당 받고 나머지 영역은 서로 공유함
    - 왜 stack은 따로 할당 받을까? 독립적인 함수 호출을 위해서 → 매개 변수와 리턴 값 등은 개별적으로 관리한다

<aside>
💡 프로세스는 자신만의 고유 공간과 자원을 할당 받아 사용하는 반면, 스레드는 다른 스레드와 공간, 자원을 공유하면서 사용함

</aside>

## 프로세스 상태

![image](https://github.com/SWM-IDLE/tech-interview/assets/78717113/8dedcbf8-5472-41af-99a5-daa79d5cb8f2)

- new(생성): 프로세스 생성 상태
    - admitted(생성 → 준비): 준비 큐가 비어있을 때 작업 스케줄러에 의해 실행
- ready(준비): 프로세스 할당 대기 상태
    - dispatch(준비 → 실행): 스케줄러에 의해 준비 큐 맨 앞에 있는 프로세스에게 CPU 할당
- running(실행): 프로세스의 명령어를 실행중인 상태
    - blocked(실행 → 대기): CPU를 할당 받은 프로세스가 입출력 작업 등으로 인해 명령을 실행할 수 없는 상태
    - interrupt(실행 → 준비): 타임 아웃 또는 스케줄링 정책에 따라 우선순위가 높은 프로세스로 CPU dispatch된 상태
    - exit(실행 → 종료): 프로세스가 CPU를 할당 받아 작업을 모두 수행한 상태
- waiting(대기): 프로세스가 어떠한 이벤트가 일어나길 기다리는 상태
    - wake up(대기 → 준비): block 상태의 프로세스가 입출력 작업이 끝나면 대기 상태에서 준비 상태가 됨
- terminated: 프로세스가 종료된 상태

## 프로세스 제어블록

- 운영체제가 시스템 내의 프로세스들을 관리하기 위해 프로세스마다 유지하는 정보를 담는 커널 내의 자료구조
- 각 프로세스가 생성될 때마다 고유의 PCB가 생성되고, 프로세스가 완료되면 PCB는 제거됨
- 프로세스의 상태 관리와 문맥 교환에 사용됨

![image](https://github.com/SWM-IDLE/tech-interview/assets/78717113/1af2ccad-e1f7-43ba-91a2-43d93952044d)

- 프로세스의 상태
- PID: 프로세스 식별자
- Program Counter: 다음 명령어의 주소
- 레지스터 저장 영역: 누산기, 인덱스 레지스터, 스택 레지스터, 범용 레지스터들과 상태 코드 포함
- CPU 스케줄링 정보
- 계정 정보: 시간 제한, 계정 번호, 프로세스 번호 등
- 입출력 상태 정보 등

# 멀티 프로세스 vs 멀티 스레드

## 멀티 프로세스

- 하나의 프로그램을 여러 개의 프로세스로 구성하여 각 프로세스가 병렬적으로 작업을 수행하는 것
- 장점) 안전성 — 메모리 침범 문제를 OS 차원에서 해결
- 단점) 각각 독립된 메모리 영역을 갖고 있어 작업량이 많을수록 오버헤드 발생, 문맥 교환으로 인한 성능 저하
    - Context Switching(문맥 교환)
        - 프로세스의 상태 정보를 저장하고 복원하는 일련의 과정

## 멀티 스레드

- 하나의 응용 프로그램에서 여러 스레드를 구성해 각 스레드가 하나의 작업을 처리하는 것
- 스레드들이 공유 메모리를 통해 다수의 작업을 동시에 처리하도록 해줌
- 장점) 독립적인 프로세스에 비해 공유 메모리만큼의 시간, 자원 손실이 감소하며 전역 변수와 정적 변수에 대한 자료 공유 가능
- 단점) 안전성 문제 — 하나의 스레드가 데이터 공간을 망가뜨리면 모든 스레드가 작동 불능 상태가 됨
    - Critical Section
        - 하나의 스레드가 공유 데이터 값을 변경하는 시점에 다른 스레드가 그 값을 읽으려할 때 발생하는 문제를 해결하기 위한 동기화 과정
        - 상호 배제, 진행, 한정된 대기를 충족해야 함

# 동기 비동기

## 동기(Synchronous)

- 요청과 그 결과가 동시에 일어남
- 시간이 얼마나 걸리던지 요청한 자리에서 결과가 주어져야 함
- 순서에 맞춰 진행되는 장점이 있지만 여러 가지 요청을 동시에 처리 불가
- 설계가 매우 간단하고 직관적이지만 결과가 주어질 때까지 아무 것도 못하고 대기해야 하는 단점

## 비동기(Asynchronous)

- 요청과 결과가 동시에 일어나지 않을 것이라는 약속
- 하나의 요청에 따른 응답을 즉시 처리하지 않아도, 그 대기 시간 동안 또 다른 요청에 대해 처리 가능한 방식
- 여러 개의 요청을 동시에 처리할 수 있는 장점이 있지만 동기 방식보다 속도가 떨어질 수 있음
- 동기 방식 보다 복잡하고 결과가 주어지는데 시간이 걸리지만 자원을 효율적으로 사용할 수 있음

## 블록/논 블록

- 결과를 받을 때까지 기다리기만 한다면 블록 상태
- 처리가 완료되었다는 전송을 받기 전까지 다른 작업을 수행한다면 논 블록 상태

## 동기/비동기 vs 블록/논 블록

- 동기/비동기: 순서와 결과에 대한 관점
    - 결과에 대한 관심, 즉 결과가 도달하자마자 처리를 해야 하는지, 아닌지
- 블록/논 블록: 제어에 대한 관점
    - 결과를 받을 때까지 다른 작업을 수행할 수 있는지, 없는지

# 프로세스 동기화

- 두 개 이상의 프로세스가 공유 자원에 동시 접근할 때 데이터 일관성을 유지하기 위한 메커니즘

## 경쟁 상태(Race Condition)

- 여러 프로세스들이 동시에 데이터에 접근하는 상황에서, 어떤 순서로 데이터에 접근하느냐에 따라 결과 값이 달라질 수 있는 상황
- Race Condition을 막고 일관성을 유지하기 위해서 프로세스 간의 실행 순서를 정해주는 메커니즘인 동기화가 필요함

## 임계 구역(Critical Section)

- 동일한 자원을 동시에 접근하는 작업을 실행하는 코드 영역 → Race Condition이 발생할 수 있는 특정 부분

## 임계 구역 문제 해결을 위한 Requirements

임계 구역으로 인해 발생하는 문제들을 해결하기 위해서는 다음 조건들을 만족해야 함

### 상호 배제(Mutual Exclusion)

- 이미 한 프로세스가 임계 구역에서 작업 중이면 모든 프로세스는 임계 구역에 진입할 수 없음
- 즉 임계 구역을 가진 스레드의 런타임이 겹치지 않게 하는 것
- Locking, Unlocking 사용
    - 데커(Dekker) 알고리즘: 어떤 프로세스가 임계 구역에 들어갈 지 결정하는 flag 변수와 어떤 것이 임계 구역을 사용 중인지 나타내는 turn 변수 활용
    - 피터슨(Peterson) 알고리즘: 데커와 유사하지만 상태 프로세스에 진입 기회 양보
    - 제과점(Bakery) 알고리즘: 가장 작은 번호표를 가진 프로세스가 진입

### 진행(Progress)

- 임계 구역에서 작업 중인 프로세스가 없을 때, 임계 구역에 진입하고자 하는 프로세스가 존재하는 경우 진입할 수 있어야 함

### 한정 대기(Bounded Waiting)

- 프로세스가 임계 구역에 들어가기 위해 요청한 후부터 그 요청이 허용될 때까지
- 다른 프로세스들이 임계 구역에 들어가는 횟수에 한계가 있어야 함
- 즉 임계 구역에 진입하려는 프로세스가 무한정 기다려서는 안됨

## 임계 구역 문제 해결 방안

### 뮤텍스(Mutex Lock)

- 임계 구역에 진입하는 프로세스는 Lock을 획득하고 임계 구역을 빠져나올 때 Lock을 방출하여 동시에 접근 불가하도록 함
- 시간적인 효율성이 떨어짐
- Busy Waiting의 문제점: 임계 구역 진입을 기다리면서 계속 CPU와 메모리를 사용함

### 세마포어(Semaphores)

- 여러 프로세스나 스레드가 임계 구역에 진입할 수 있는 Signaling 메커니즘
- 카운터(Counter)를 이용해 동시에 자원에 접근할 수 있는 프로세스를 제한
    - 주로 S라는 정수형 변수로 나타내며, 이는 사용 가능한 자원의 개수를 의미함
- 세마포어 변수는 오직 두 개의 atomic한 연산을 통해서 접근할 수 있음
    - P 연산: 공유 데이터를 획득하는 과정
    - V 연산: 반납하는 과정
    - 한 프로세스가 세마포어 변수를 수정할 때 다른 프로세스가 동시에 같은 세마포어 변수를 수정할 수 없음
    - Counting Semaphore
        - 가용한 개수를 가진 자원
- wait, signal로 구현
    - wait이 먼저 호출되어 임계 구역에 들어갈 수 있는지, 우선적으로 실행되어야 할 스레드가 있는지 확인
- Counting 세마포어
    - 정수 값의 범위가 0 이상으로 제한이 없음
    - 주로 자원의 개수를 세는 데 사용함
- Binary 세마포어
    - 정수 값이 오직 0 또는 1이다
    - Mutex Lock과 동일한 역할을 가지나 차이점이 존재함
        - 이진 세마포어는 신호(signalling) 메커니즘에 기반한 기능이지만 뮤텍스는 잠금(locking) 메커니즘에 기반한 기능
        - 여러 스레드가 한 번에 Binary 세마포어를 획득할 수 있지만 뮤텍스는 하나의 스레드만 획득 가능
        - 다른 스레드/프로세스가 Binary 세마포어를 unlock할 수 있기 때문에 뮤텍스보다 빠름 — 뮤텍스는 획득한 스레드만 unlock 가능
        - 즉 binary 세마포어는 소유권이 없지만 뮤텍스는 소유권이 있음

### 모니터(Monitor)

- 공유 자원을 내부로 숨기고, 공유 자원에 접근하기 위한 인터페이스만 제공 → 시스템 호출
    - 요청 받은 작업을 모니터 큐에 저장
    - 시스템은 모니터 큐의 데이터를 순서대로 처리
    - 결과만 해당 프로세스에 알려줌
    
    ![image](https://github.com/SWM-IDLE/tech-interview/assets/78717113/14827920-4603-4393-966e-31fc1f9b564c)
    
- 세마포어와 같이 P, V 연산을 사용하지 않고 모니터에 작업을 요청
- 모니터가 사용하는 상태 변수
    - wait() 연산: 모니터 큐에서 자신의 차례가 올 때까지 기다림
    - signal() 연산: 모니터 큐에서 기다리는 다음 프로세스에 순서를 넘겨줌

## 교착 상태(Deadlock)

- 둘 이상의 프로세스가 서로 상대방에 의해 충족될 수 있는 event를 영원히 기다리는 현상
- 세마포어가 Ready Queue를 가지고 있고, 둘 이상의 프로세스가 임계 구역 진입을 무한정 기다리며, 임계 구역에서 실행되는 프로세스는 진입 대기 중인 프로세스가 실행되어야만 빠져나올 수 있는 상황
- 교착 상태의 필요 충분 조건 — 다음 4개의 조건이 모두 만족되어야 함

### 상호 배제(Mutual Exclusion)

- 한 번에 한 개의 프로세스만이 공유 자원을 사용할 수 있어야 함

### 점유와 대기(Hold and Wait)

- 어떤 프로세스가 하나 이상의 자원을 점유하고 있으면서 다른 프로세스가 가지고 있는 자원을 기다리고 있음

### 비선점(Non-Preemption)

- 프로세스가 작업을 마친 후 자원을 자발적으로 반환할 때까지 기다림 — 강제로 자원을 빼앗을 수 없음

### 환형 대기(Circular Wait)

- Hold and Wait 관계의 프로세스들이 순환 형태로 서로를 기다림

## 교착 상태의 대처 방안

### 예방 기법

- 교착 상태가 발생하지 않도록 사전에 시스템을 제어하는 방법
- 교착 상태 발생의 네 가지 조건 중 어느 하나를 제거함으로써 수행됨
    - 상호 배제 부정: 한 번에 여러 프로세스가 공유 자원을 사용할 수 있게 함
    - 점유와 대기 부정: 프로세스가 실행되기 전 필요한 모든 자원을 할당함
    - 비선점 부정: 자원을 점유하고 있는 프로세스가 다른 자원을 요구할 때 가진 자원을 반납힘
    - 순환 대기 부정: 자원에 고유 번호를 할당 한 뒤 한쪽 방향으로만 자원 요구
- 자원 낭비가 가장 심한 기법

### 회피 기법

- 교착 상태가 발생할 가능성을 배제하지 않고 교착 상태가 발생하면 적절히 피해나가는 방법
- 은행원 알고리즘
    - 프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 뒤에도 안정 상태로 남아있게 되는지 사전에 검사함
    - 안정 상태라면 자원 할당, 아니면 다른 프로세스들이 자원을 반환할 때까지 대기

### 탐지 기법

- 자원 할당 그래프를 통해 교착 상태를 탐지함
- 자원 요청 시, 탐지 알고리즘을 실행시키기 때문에 그에 대한 오버헤드가 발생함

### 회복 기법

- 교착 상태를 일으킨 프로세스를 종료하거나, 할당된 자원을 반환해 회복시키는 방법
- 프로세스 종료 방법
    - 교착 상태의 프로세스를 모두 중지
    - 교착 상태가 제거될 때까지 하나씩 프로세스 중지
- 자원 선점 방법
    - 교착 상태의 프로세스를 일시정지하고, 점유하고 있는 자원을 선점해 다른 프로세스에게 할당
    - 우선 순위가 낮은 프로세스나 수행 횟수가 적은 프로세스 위주로 자원 선점

## 기아 상태

- 특정 프로세스의 우선 순위가 낮아서 원하는 자원을 계속 할당 받지 못하는 상태
    - 교착 상태: 여러 프로세스가 동일 자원 점유를 요청할 때 발생
    - 기아 상태: 여러 프로세스가 부족한 자원을 점유하기 위해 경쟁할 때 발생
- 해결 방법
    - 프로세스 우선순위를 수시로 변경
    - 오래 기다린 프로세스의 우선순위를 높이기(Aging 기법)
    - 우선순위가 아닌 요청 순서대로 처리하는 요청 큐 사용

## 식사하는 철학자 문제

![image](https://github.com/SWM-IDLE/tech-interview/assets/78717113/75187f07-3de0-4ea6-b83b-10f4172720e4)

- 규칙 상세
    1. 일정 시간 생각을 한다.
    2. 왼쪽 포크가 사용 가능해질 때까지 대기한다. 만약 사용 가능하다면 집어든다.
    3. 오른쪽 포크가 사용 가능해질 때까지 대기한다. 만약 사용 가능하다면 집어든다.
    4. 양쪽 포크를 잡으면 일정 시간만큼 식사를 한다.
    5. 오른쪽 포크를 내려놓는다.
    6. 왼쪽 포크를 내려놓는다.
    7. 다시 1번으로 돌아간다
- 모든 철학자들이 2개의 포크를 갖지 못하고 서로를 영원히 기다리고만 있는 교착 상태에 빠짐
- OS 차원의 해결법
    - 한 철학자가 포크를 잡는다면, 반대쪽 포크를 잡을 때까지 행동권을 넘길 수 없음 → CPU의 인터럽트를 무시
    - 커널 레벨에서만 가능하지만 멀티쓰레드 환경이라면 세마포어나 뮤텍스 등을 통해 임계 구역의 교착 상태 방지 가능
- 하드웨어 아키텍처 차원의 해결법
    - 양쪽 포크를 동시에 잡게 하는 명령어 사용 → 쪼갤 수 없는 명령어(Atomic Instruction)
- 소프트웨어 차원의 해결법
    - 타임아웃 설정: 일정 시간 내에 다른 쪽 포크를 획득하지 못한다면 포크를 반납함. 제일 간단하지만 타임아웃에 따른 딜레이가 있음
    - 철학자 중 한명은 포크를 오른쪽부터 잡게 함. 주도권이 다시 상대에게 돌아가 교착 상태 방지
    - 포크마다 고유한 값(해시)을 부여해 고유 값이 높은 순서대로 포크를 집게 함. 절대로 모든 철학자가 하나의 포크를 잡고 대기하지 않음

# 스케줄러

어떤 프로세스에게 자원을 할당할지 결정하는 운영체제 커널의 모듈

- Job Queue: 현재 시스템 내에 있는 모든 프로세스의 집합
- Ready Queue: 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
- Device Queue: 각 장치마다 I/O 작업을 대기하고 있는 프로세스의 집합

# 스케줄러의 종류

## 장기 스케줄러(Job Scheduler)

- 메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장
- 임시로 저장된 프로세스 중 **어떤 프로세스에 메모리를 할당하여 Ready Queue로 보낼지** 결정하는 역할
- **메모리와 디스크 사이의 스케줄링** 담당
- 수십 초 내지 수 분 단위로 가끔 호출되므로 상대적으로 느린 속도를 허용
- 프로세스에 메모리 및 각종 리소스를 할당
- Degree of Multiprogramming(DOM) 제어: 실행중인 프로세스의 수 제어
- 프로세스의 상태: New → Ready

## 단기 스케줄러(CPU Scheduler)

- **CPU와 메모리 사이의 스케줄링** 담당
- ms 이하의 시간 단위로 매우 빈번하게 호출되므로 수행 속도가 빨라야 함
- **Ready Queue에 존재한 프로세스 중 어떤 프로세스를 Running 시킬지** 결정
- 미리 정한 스케줄링 알고리즘에 따라 CPU를 할당(Dispatch)할 프로세스 선택
- 프로세스의 상태: Ready → Running → Waiting → Ready

## 중기 스케줄러

- **메모리에 적재된 프로세스의 수를 동적으로 조절**하기 위해 추가된 스케줄러
- 너무 많은 프로그램이 동시에 올라가는 것을 조절해 메모리의 가중을 완화
- CPU를 차지하기 위한 경쟁이 심해질 때, 우선순위가 낮은 프로세스들을 잠시 제거한 뒤 나중에 경쟁이 완화되었을 때 다시 디스크에서 메모리로 불러와 중단된 지점부터 실행(Swapping)
- 프로세스의 상태: Ready → Suspended
    - **Suspended(Stopped)**: 외부적인 이유로 프로세스의 수행이 정지되어 메모리에서 내려간(swap out) 상태
    - Blocked 상태는 다른 I/O 작업을 기다리는 상태이기 때문에 스스로 Ready 상태로 돌아갈 수 있지만, 이 상태는 외부적인 이유로 suspending 되었기 때문에 스스로 돌아갈 수 없음

![image](https://github.com/SWM-IDLE/tech-interview/assets/78717113/f5809d45-fd28-4b66-8fb4-ca498f0968fe)

# CPU 스케줄러

## 비선점형 스케줄링(Non-preemptive)

- 어떤 프로세스가 **CPU를 할당받으면** 그 프로세스가 종료되거나 입출력 요구가 발생해 자발적으로 중지될 때까지 **계속 실행되도록 보장**
- 순서대로 처리되는 공정성
- 다음에 처리해야할 프로세스와 관계 없이 응답 시간 예상 가능
- 선점 방식보다 스케줄러 호출 빈도도 낮고 문맥 교환의 오버헤드가 적음
- 일괄 처리(Batch) 시스템에 적합
- CPU 사용시간이 긴 하나의 프로세스가 여러 프로세스를 오래 대기 → 처리율이 떨어짐
- 비선점 스케줄링 종류
    - FCFS(First Come First Served)
    - SJF(Shortest Job First)
    - HRRN(Highest Response Ratio Next)

## 선점형 스케줄링(Preemptive)

- 어떤 프로세스가 **CPU를 할당받아 실행 중에 있어도** 다른 프로세스가 실행중인 프로세스를 중지하고 **CPU를 강제로 점유**할 수 있음
- 모든 프로세스에게 CPU 사용시간을 동일하게 부여할 수 있음
- 빠른 응답 시간을 요하는 대화식(Interactive) 시분할(Time Sharing) 시스템에 적합
- **운영체제가 프로세서 자원을 선점**하고 있다가 각 프로세스의 요청이 있을 때 특정 요건들을 기준으로 자원을 배분함
- 선점 스케줄링 종류
    - RR(Round Robin)
    - SRTF(Shortest Remaining-Time First)
    - 다단계 큐 스케줄링
    - 다단계 피드백 큐 스케줄링
    - RM(Rate Monotonic)
    - EDF(Earliest Deadline First)

## FCFS(First Come First Served)

- 먼저 자원을 요청한 프로세스에게 자원을 할당 → 순서대로 처리
- 비선점형 스케줄링
- **convoy effect**: 소요 시간이 긴 프로세스가 먼저 도달하여 효율성을 낮춤

## SJF(Shortest Job First)

- CPU 사용 시간이 짧은 프로세스에게 먼저 자원을 할당함
- 비선점형 스케줄링
- **starvation**: 사용시간이 긴 프로세스는 거의 영원히 CPU를 할당받지 못함

## SRTF(Shortest Remaining Time First)

- SJF와 비슷하지만 새로운 프로세스의 CPU 사용 시간이 현재 실행중인 프로세스보다 짧으면 새로운 프로세스를 먼저 실행함
- 선점형 스케줄링
- 새로운 프로세스가 도착할 때마다 CPU 사용 시간을 확인해야 함

## Priority Scheduling

- 우선순위가 높은 프로세스에게 CPU를 할당 (정수 값이 낮을 수록 우선순위 높음)
- 우선 순위는 시간 제한, 메모리 요구량, 프로세스의 중요도, 자원 사용 비용 등에 따라 결정됨
- 선점형 스케줄링: 더 높은 우선순위의 프로세스가 도착하면 CPU를 선점
- 비선점형 스케줄링: 더 높은 우선순위의 프로세스가 도착하면 Ready Queue의 Head에 넣음
- starvation 현상 발생 → aging 기법으로 해결
- 무기한 봉쇄: 실행 준비는 되어있으나 CPU를 사용하지 못하는 프로세를 CPU가 무기한 대기시키는 상태

## RR(Round Robin)

- 현대적인 CPU 스케줄링
- 각 프로세스는 동일한 크기의 할당 시간(time quantum)을 갖게 됨
    - time quantum이 너무 커지면 FCFS와 같아지고, 너무 작아지면 잦은 문맥 교환으로 인한 오버헤드 발생
    - 적당한 time quantum 설정이 중요
- 할당 시간이 지나면 프로세스는 선점당하고 Ready Queue의 제일 뒤에 가서 다시 줄을 섬
- CPU 사용 시간이 랜덤한 프로세스들이 섞여있을 경우에 효율적
- RR이 가능한 이유는 프로세스의 context를 save할 수 있기 때문
- 어떤 프로세스도 (n-1)q 이상 기다리지 않음 → 공정한 스케줄링

# 메모리 관리 전략

- 제한된 물리 메모리의 효율적인 사용과 메모리 참조 방식을 제공하기 위한 전략

## 효과적인 메모리 사용

### 동적 적재(Dynamic Loading)

- 프로그램 실행에 반드시 필요한 루틴과 데이터만 적재
- 모든 루틴(오류 처리), 데이터(배열) 등은 필요 시에만 적재

### 동적 연결(Dynamic Linking)

- 라이브러리 루틴 연결을 컴파일 시점이 아닌 실행 시점까지 미룸

### 스와핑(Swapping)

- CPU에서 실행중이지 않는 프로세스는 저장 장치의 Swap 영역으로 이동(Swap in/Swap out)하여 메모리 확보
- 문맥 교환으로 인한 오버헤드가 발생할 수 있고 속도가 느리지만 메모리 공간 확보에는 효율적

## 연속 메모리 할당

- 프로세스를 메모리에 연속적으로 할당하는 기법
- 할당과 제거를 반복하다보면 외부 단편화가 발생
- 연속 메모리 할당에서 외부 단편화를 줄이기 위한 할당 방식
    - 최초 적합: 가장 처음 만나는 빈 공간에 할당
    - 최적 적합: 공간 차이가 가장 적은 곳에 할당
    - 최악 적합: 공간 차이가 가장 큰 곳에 할당 → 차이 공간에 다른 프로세스 할당 가능

## 단편화(Fragmentation)

- 메모리 공간이 충분해도 프로세스가 메모리에 적재되지 못해 메모리 낭비

### 외부 단편화

- 가변 분할 방식에서 메모리에 프로세스가 적재, 제거되는 일이 반복되면서 여유 공간이 조각으로 흩어짐(Scattered Holes)

### 내부 단편화

- 고정 분할 방식에서 프로세스가 실제 필요한 메모리보다 더 큰 메모리를 할당받음

### 압축(Compaction)

- 외부 단편화 해소를 위해 Scattered Holes를 모으는 방법
- 합치는 과정에서 프로세스를 정지시키고 한쪽으로 이동 → 비효율적
- 어느 자유 공간으로 모을지 결정하는 알고리즘 모호

## Paging

- 비연속 메모리 할당
- 메모리 공간이 연속적으로 할당되어야 한다는 제약 조건을 없애는 메모리 관리 전략
- 논리 메모리는 고정 크기의 페이지, 물리 메모리는 고정 크기의 프레임 블록으로 나누어 관리
- 페이지 테이블을 가짐
- 프로세스가 사용하는 공간을 논리 메모리에서 여러 개의 페이지로 나누어 관리 → 개별 페이지는 순서에 상관 없이 물리 메모리에 있는 프레임에 매핑되어 저장
- MMU(Memory Management Unit)의 재배치 레지스터 방식을 활용해 CPU로 하여금 프로세스가 연속된 메모리에 할당된 것처럼 인식
- 내부 단편화 발생

## Segmentation

- 비연속 메모리 할당
- 페이징 기법과 반대로 논리 메모리와 물리 메모리를 같은 크기의 블록이 아닌, 서로 다른 크기의 논리적 단위인 세그먼트로 분할
- 세그먼트 테이블을 가짐 — 크기가 일정하지 않기 때문에 limit 정보가 추가됨
- 외부 단편화 발생

### 세그멘테이션 페이징 혼용 기법

- 단편화를 줄이기 위해 프로세스를 세그먼트로 나눈 다음, 세그먼트를 다시 페이지 단위로 나누어 관리
- 매핑 테이블을 두 번 거쳐야 하므로 속도가 느림

# 가상 메모리

- 프로세스 전체가 메모리 내에 올라오지 않더라도 실행 가능하도록 하는 기법
- 프로그램이 물리 메모리보다 커도 된다는 장점

## 가상 메모리 개발 배경

- 코드를 전부 물리 메모리에 올려야 함 → 메모리 용량보다 큰 프로그램은 실행 불가
- 프로그램의 일부분만 메모리에 올릴 수 있다면?
    - 물리 메모리 크기에 제약 받지 않게 됨
    - 더 많은 프로그램들을 동시에 실행 가능 → 응답 시간 유지, CPU 이용율과 처리율 향상
    - Swap에 필요한 입출력이 줄어들기 때문에 프로그램들이 빠르게 실행됨

## 가상 메모리가 하는 일

- 물리 메모리 개념과 논리 메모리 개념을 분리
- 작은 메모리를 가지고도 큰 가상 주소 공간을 제공 가능

### 가상 주소 공간 제공

- 한 프로세스가 메모리에 저장되는 논리적인 모습을 가상 메모리에 구현한 공간
- 프로세스가 요구하는 메모리 공간을 가상 메모리에서 제공함으로써 현재 직접적으로 필요치 않은 메모리 공간은 실제 물리 메모리에 올리지 않음

### 프로세스간의 페이지 공유

- 시스템 라이브러리가 올라가 있는 물리 메모리 페이지들은 모든 프로세스에서 공유됨 — 가상 주소 공간에서는 독립적으로 보임
- 프로세스 간의 메모리 공유를 가능하게 하고, 공유 메모리를 통해 통신할 수 있음
- fork()를 통한 프로세스 생성 과정에서 페이지들이 공유되는 것을 가능하게 함

## Demand Paging(요구 페이징)

- 프로그램 실행 시, 초기에 필요한 것들만 물리 메모리에 적재하는 전략
- 프로세스 내 개별 페이지들은 페이저(pager)에 의해 관리됨
    - pager는 프로세스 실행에 실제 필요한 페이지들만 메모리로 읽어옴

## 페이지 교체

- 프로세스 동작에 필요한 페이지를 요청하는 과정에서 page fault(페이지 부재)가 발생 → 원하는 페이지를 보조저장장치에서 가져옴
- 이때 물리 메모리가 모두 사용 중이라면 페이지 교체가 이루어져야 함
- 물리 메모리 상에서 희생 페이지를 알고리즘을 통해 선택 → 희생 페이지를 디스크로 옮김 → 그 자리에 필요한 페이지를 올림

## FIFO 페이지 교체

- 먼저 물리 메모리에 들어온 순서대로 페이지 교체 시점에 먼저 나감
- 오래된 페이지가 항상 불필요하지 않은 정보를 포함하지 않을 수 있음 → 활발하게 사용되는 페이지를 교체해 페이지 부재율을 높일 수 있음
- Belady의 모순: 페이지 프레임의 개수를 늘려도 되려 페이지 부재가 더 많이 발생

## 최적 페이지 교체

- 앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체
- 가장 낮은 페이지 부재율을 보장하지만 구현이 어려움
- 주로 비교 연구 목적(이와 비슷한 결과일수록 좋은 알고리즘)

## LRU(Least Recently Used) 페이지 교체

- 가장 오랫동안 사용되지 않을 페이지를 선택해 교체
- FIFO 보다 우수하나 최적 알고리즘보다는 못함

## LFU(Least Frequently Used) 페이지 교체

- 참조 횟수가 가장 적은 페이지를 교체
- 어떤 프로세스가 특정 페이지를 집중적으로 사용하다가 다른 기능을 사용하게 되는 경우 비효율적
- 최적 알고리즘에 근사하지 못해 잘 쓰이지 않음

## MFU(Most Frequently Used) 페이지 교체

- 참조 횟수가 가장 작은 페이지가 최근에 메모리에 올라왔고, 앞으로 계속 사용될 것이라는 가정
- 최적 알고리즘에 근사하지 못해 잘 쓰이지 않음

# 캐시 메모리(Cache Memory)

- 주기억장치에서 자주 사용하는 프로그램과 데이터를 저장해두어 속도를 빠르게 하는 메모리
- 속도가 빠른 장치와 느린 장치간의 속도 차에 따른 병목 현상을 줄이기 위한 범용 메모리 — CPU가 어떤 데이터를 원하는지 예측 필요
- 주기억장치와 CPU 사이에 위치하며, 캐시 기억장치와 주기억장치에서 정보를 옮기는 것을 Mapping 이라고 함
    - 직접 매핑: 주기억장치들의 블록들이 지정된 한 개의 캐시 라인으로만 사상됨 → 간단하지만 적중률이 낮아질 수 있음
    - 연관 매핑: 직접 매핑의 단점 보완 → 모든 태그들을 병렬로 검사하는데 비용이 높아 잘 안씀
    - 집합 연관 매핑: 직접 매핑과 연관 매핑의 장점만을 취한 방식
- 캐시 메모리 사용 시 주기억장치 접근 횟수가 줄어 컴퓨터의 처리속도 향상
- 캐시가 효율적으로 동작하려면 캐시의 적중률(Hit-rate)를 극대회 시켜야 함

![image](https://github.com/SWM-IDLE/tech-interview/assets/78717113/b0192c7f-7df4-444b-a463-43cbf20add93)

## Locality(지역성)

- 데이터 접근이 시간적, 혹은 공간적으로 가깝게 일어나는 것
- 캐시의 지역성: 기억장치 내의 정보를 균일하게 access하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성
- 시간적 지역성
    - 특정 데이터가 한번 접근되면, 곧 다시 접근하는 특성
    - 같은 주소에 여러 차례 읽기 쓰기 수행 시 작은 캐시로 높은 효율성
- 공간적 지역성
    - 참조된 주소와 인접한 주소의 내용이 다시 참조되는 특성
    - 캐시에 이미 저장된 같은 블록의 데이터에 접근

## Caching Line

- 캐시에 저장된 데이터가 어디에 저장되어 있는지 알기 위함
- 캐시에 저장하는 데이터에는 데이터의 메모리 주소 등을 기록해 둔 태그를 달아놓아야 함 → 이러한 태그들의 묶음이 캐싱 라인
- 캐싱 라인의 종류
    - Direct Map: 같은 태그는 한 개의 캐시 공간만 사용 → 데이터를 찾긴 빠르지만 충돌이 자주 일어남
    - Full Associative: 태그와 관계 없이 비어있는 캐시 메모리를 탐색해서 집어넣고, 데이터가 있는지 찾을 때도 순차적으로 탐색해서 가져옴 → 충돌 위험은 적지만 순차탐색 시간 발생
    - Set Associative: Full Associcative와 Direct Map의 장점들을 고려해 만들어짐 → 테이블의 개수에 따라 n-way Set Associative이며 n번 만큼 탐색해서 Direct Map보다 시간이 좀 더 걸리지만 충돌 위험은 줄어듬

---

### 헷갈리는 부분

<aside>
❓ 세마포어는 Busy Waiting이 일어나는 걸까 안일어나는 걸까

</aside>

- 세마포어에서 Block & Wakeup 방식으로 Busy Waiting 해결 가능
- 임계 구역으로의 진입에 실패한 프로세스를 기다리게 하지 않고 Block 시킨 뒤, 임계 구역에 자리가 나면 다시 깨워줌으로써 Busy Waiting에서의 CPU 낭비 문제 해결
- 일반적으로 Busy Waiting이 비효율적이지만, 임계 구역이 매우 짧은 경우 Block & Wakeup의 오버헤드가 더 커질 수 있음
